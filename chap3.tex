\chapter{Apple's Implementation}

A lot of Apple's source code is open-sourced\cite{apple_open_source} which includes their implementation of the Objective-C run-time among others.

First thing that comes across mind when studying Apple's source codes is the run-time's history - there's a lot of historical code that ensures backward compatibility. For example, some code from the NeXT era and a port to Windows can be found here. NeXT had a set of APIs called OpenStep (which is the predecessor of today's Cocoa framework on OS X), which was written in Objective-C and was aiming to run on virtually any reasonable system\cite{openstep_wiki}. Also, some of Apple's own software for Windows, such as Safari, is written in Objective-C, hence the run-time needs to be compilable under Windows as well\cite{safari_windows}.

While the legacy code is understandable as it is required to maintain binary compatibility of all existing binaries and the portability is generally an objective of this work, neither is done in a very clean fashion.

The code that was used by the run-time before introduction of Objective-C 2.0 in 2007, is referred to as the \emph{old run-time}. The code that is part of the Objective-C 2.0 (and later) if referred to as the \emph{new run-time}.

All code is duplicated, one part serving compilation of the old run-time and the second part serving compilation of the new run-time. For example, files such as \verb=objc-runtime-old.m= and \verb=objc-runtime-new.mm= can be found. Note the \verb=.mm= file extension on the new run-time file suggesting presence of C++, which will be described later.

\section{Portability}

The portability of the run-time can be divided in two parts - portability in terms of operating systems and in terms of the CPU architecture.

\subsection{CPU Portability}

Historically, Objective-C has been run on quite a few architectures - Intel x86, and Sun microchips from the NeXT era, PPC, Intel x86-64 and more recently ARM chips.

The \verb=objc_msgSend= function and its relatives are written in assembly and hence have to be rewritten for each new architecture.

\subsection{OS portability}

The OS portability is ensured by a rather large \verb=#ifdef= - \verb=#else= - \verb=#endif= statement that uses macros and static inline functions to define aliases to some OS X-specific functions on Windows, such as \verb=malloc_zone_malloc= or even POSIX-specific functions, like \verb=issetguid=. Two examples follow.

\subsection{Example 1 - malloc}
On OS X, the malloc function is extended to support memory zones\cite{apple_malloc_man_page}. By creating a zone, a new heap is created. The heap can be destroyed entirely at once. It has a very limited usage nowadays, but back in the day when computers had only a little memory, it was useful to allocate temporary objects (e.g.\ during a specific calculation) in its own zone, freeing it as a whole when done with these objects. For example, the \verb=NSMenu=, which is a class representing a menu on OS X, implements a class method \verb=+menuZone= which returns a zone that is used for menu allocations - considering that a menu is a UI element that gets displayed on the screen for only a short period of time, it is a good idea to store all memory used to represent it in a separate zone, freeing all the memory when the menu is dismissed and hence preventing memory fragmentation. Unfortunately, when releasing a chunk of memory like this at once, the \verb=-dealloc= method doesn't get called, which could result in memory leaks. The zones were also supposed to be used to add garbage collection support to Objective-C back in the NeXT days, which never happened, though.

As Windows supports only the regular \verb=malloc= function, this had to be solved - and it has been solved rather radically, by defining the \verb=malloc_*= functions as static inline functions that call the Windows API functions. The following lines of code may be found in file \verb=objc-os.h=:

\begin{verbatim}
static inline void *malloc_zone_malloc(malloc_zone_t z, 
                                              size_t size) { 
    return malloc(size); 
}
\end{verbatim}

While it is functional, if Microsoft ever decided to implement zones into its version of malloc, it would break the code as it would result in duplicate symbol definition. Moreover, there is another function defined in the source code file \verb=objc-class.m=:

\begin{verbatim}
void *_malloc_internal(size_t size) {
    return malloc_zone_malloc(_objc_internal_zone(), size);
}
\end{verbatim}

It would make much more sense to simply declare functions that would deal with the portability issue themselves, i.e.\ moving the \verb=#if=-\verb=#else= construct inside each function which would result in a more readable code.

\subsection{Example 2 - issetguid}
The other example is how is the \verb=issetguid= function ported to the Windows environment:

\begin{verbatim}
#define issetugid() 0
\end{verbatim}

\section{Limitations}
There are several limitations that can be found in the code that may present an obstacle when compiling the run-time on a new platform.

\subsection{16B Object Minimum Size}
Apple supplies several large libraries (or as they call them, frameworks), that a vast majority of applications build upon. In particular, the CoreFoundation and Foundation frameworks are used basically by every application in the system (if not directly, then at least indirectly).

CoreFoundation, although it implements many Objective-C classes as can be easily verified using the class-dump tool\cite{class_dump}, only provides C exports and headers, with the Objective-C classes being used privately.

On the other hand, the Foundation framework, CoreFoundation's counterpart, is mainly an Objective-C framework, providing object-oriented access to the mainly C-based CoreFoundation and officially allows access to some Objective-C classes declared in CoreFoundation.

For example, \verb=CFStringRef= is a pointer to a structure used by the CoreFoundation framework to represent a string. The Foundation framework has a \verb=NSString= class, which does generally the same. In order to prevent unnecessary code duplication as well as data conversions when using CoreFoundation functions (which accept \verb=CFStringRef=) from Objective-C code, toll-free bridging has been introduced.

There is an intricate mechanism behind it, which requires direct support from both the Foundation and CoreFoundation frameworks (so one cannot create toll-free bridge of other (Core)Foundation classes that aren't bridged yet himself or herself)\cite{toll_free_bridging_internals}, but instances of classes that do support toll-free bridging, can be simply casted to their CoreFoundation counterparts and vice versa. Using the \verb=CFStringRef=/\verb=NSString= couple, this code if fully valid:

\begin{figure}[H]
\begin{verbatim}
NSString *myString = @"Hello World!";
CFStringRef duplicatedString = CFStringCreateCopy(NULL, 
                                    (CFStringRef)myString);
NSString *duplicatedString2 = (NSString*)duplicatedString;
\end{verbatim}
  \centering{}
  \caption{An example of toll-free bridging.}
  \label{fig:toll_free_bridging}
\end{figure}

While this is very convenient to every OS X (or iOS) developer, it poses an unexpected limitation: all object instances need to have the same minimum size as CoreFoundation ``objects" - 16 bytes, which is noted in a comment in \verb=objc-class.m= file within the \verb=_class_createInstancesFromZone= function. True that 16 bytes is not that much in these days, but given that 4 \verb=NSObject= objects could fit into one on a 32-bit computer, the space adds up.

\subsection{Dynamic Loader Support}
As it is faster to simply copy the class data from the binary image than to construct the classes using the run-time functions (on OS X from the \verb=__OBJC= section in particular), Apple's implementation contains a set of functions that are called by the dynamic loader (\verb=dyld=) to load classes from the binary image, link them to their superclasses and to register them with the run-time.

This, however, adds \verb=dyld= to the list of library dependencies, which is transitively required by \verb=libSystem=\footnote{Basic system library on OS X that every application needs to be linked to.} anyway, but it adds dependencies to the code itself.

More portable code would declare structures to be passed to the run-time when loading a binary, and the dynamic loader would pass those to the run-time. Instead, the dynamic loader passes the binary image header pointer to the run-time, making the run-time crawl through the binary image headers for Objective-C data itself.

In general, the dynamic loader support in Apple's run-time poses a question, which party is responsible exactly for which part of the binary loading. It also puts a light on the binary compatibility question. If the internal structures representing a class change, the binary will not launch.

Creating classes manually using the run-time methods ensures binary compatibility, while slows down binary loading significantly and makes one ask where should be the class information stored. One option would be for the compiler to generate a function with a specific name that would get called by the dynamic loader, or called it manually before anything else in the \verb=main= of your program (which might interfere with the \verb=__attribute__((constructor))= functions, though).

\subsection{C++ Influences}
The newest parts of the Objective-C run-time use many C++ features, such as methods on structures, some C++ classes, e.g. \verb=vector= and the run-time tries to unify Objective-C and C++ exceptions using the \verb=unwind= library.

While this may help to clean up the code a little, it adds additional dependencies on C++ libraries.

\section{Summary}
Apple's implementation is riddled with a lot of obscure code and other very specific details - for example, when the class images are stored in the \verb=__OBJC= binary section, the superclass field is pointing to a string containing the name of that superclass - when the run-time is connecting the images, it is casting the superclasses pointer to \verb=char *=, to read the superclass name, which is not a very clean solution. For example, the \'Etoil'e run-time uses two differently named structures for a cleaner cast. 

Moreover, the documentation is very brief, not every function has a description of what it exactly does, or only has a very short note that it is used from a different function somewhere else in the code. The GCC implementation of the run-time is much better documented in this matter.
